{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd6648f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6dd70b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45cb3f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"The quick brown fox jumped over the lazy dog\",\n",
    "    \"I love natural language processing\",\n",
    "    \"The dog barked loudly at the stranger\",\n",
    "    \"She sells sea shells on the sea shore\",\n",
    "    \"Machine learning is fascinating\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b1ba0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_corpus = [nltk.word_tokenize(doc.lower()) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01cef6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = [token for doc in token_corpus for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff1c484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(flattened))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02164c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['at',\n",
       " 'barked',\n",
       " 'brown',\n",
       " 'dog',\n",
       " 'fascinating',\n",
       " 'fox',\n",
       " 'i',\n",
       " 'is',\n",
       " 'jumped',\n",
       " 'language',\n",
       " 'lazy',\n",
       " 'learning',\n",
       " 'loudly',\n",
       " 'love',\n",
       " 'machine',\n",
       " 'natural',\n",
       " 'on',\n",
       " 'over',\n",
       " 'processing',\n",
       " 'quick',\n",
       " 'sea',\n",
       " 'sells',\n",
       " 'she',\n",
       " 'shells',\n",
       " 'shore',\n",
       " 'stranger',\n",
       " 'the']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7efe658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_2_idx = {word:i for i, word in enumerate(vocab)}\n",
    "idx_2_word = {i:word for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2200ab65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary :  {'at': 0, 'barked': 1, 'brown': 2, 'dog': 3, 'fascinating': 4, 'fox': 5, 'i': 6, 'is': 7, 'jumped': 8, 'language': 9, 'lazy': 10, 'learning': 11, 'loudly': 12, 'love': 13, 'machine': 14, 'natural': 15, 'on': 16, 'over': 17, 'processing': 18, 'quick': 19, 'sea': 20, 'sells': 21, 'she': 22, 'shells': 23, 'shore': 24, 'stranger': 25, 'the': 26}\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "print(\"Vocabulary : \" , word_2_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a88723c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cbow_data(tokenized_sentences, window_size=2):\n",
    "    data = []\n",
    "    for sentence in tokenized_sentences:\n",
    "        for i in range(window_size, len(sentence) - window_size):\n",
    "            context = [\n",
    "                sentence[i - 2],\n",
    "                sentence[i - 1],\n",
    "                sentence[i + 1],\n",
    "                sentence[i + 2]\n",
    "            ]\n",
    "            target = sentence[i]\n",
    "            data.append((\n",
    "                [word_2_idx[w] for w in context],\n",
    "                word_2_idx[target]\n",
    "            ))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4381b8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example (context, target): ([26, 19, 5, 8], 2)\n"
     ]
    }
   ],
   "source": [
    "cbow_data = generate_cbow_data(token_corpus)\n",
    "print(\"Example (context, target):\", cbow_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d648cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
