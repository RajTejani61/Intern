{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "555ce9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\torch_env\\lib\\site-packages\\torchtext\\vocab\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "c:\\ProgramData\\anaconda3\\envs\\torch_env\\lib\\site-packages\\torchtext\\utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchtext\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "import spacy\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325d7230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a05d18a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'cotton', 'cotton-oil', 'cpi', 'cpu', 'crude', 'dfl', 'dlr', 'dmk', 'earn', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-oil', 'heat', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-oil', 'livestock', 'lumber', 'meal-feed', 'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-oil', 'palmkernel', 'pet-chem', 'platinum', 'potato', 'propane', 'rand', 'rape-oil', 'rapeseed', 'reserves', 'retail', 'rice', 'rubber', 'rye', 'ship', 'silver', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tea', 'tin', 'trade', 'veg-oil', 'wheat', 'wpi', 'yen', 'zinc']\n",
      "['test/14826', 'test/14828', 'test/14829', 'test/14832', 'test/14833']\n"
     ]
    }
   ],
   "source": [
    "print(reuters.categories())\n",
    "print(reuters.fileids()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "358bde27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RIFT\n",
      "  Mounting trade friction between the\n",
      "  U.S. And Japan has raised fears among many of Asia's exporting\n",
      "  nations that the row could inflict far-reaching economic\n",
      "  damage, businessmen and officials said.\n",
      "      They told Reuter correspondents in Asian capitals a U.S.\n",
      "  Move against Japan might boost protectionist sentiment in the\n",
      "  U.S. And lead to curbs on American imports of their products.\n",
      "      But some exporters said that while the conflict would hurt\n",
      "  them in the long-run, in the short-term Tokyo's loss might be\n",
      "  their gain.\n",
      "      The U.S. Has said it will impose 300 mln dlrs of tariffs on\n",
      "  imports of Japanese electronics goods on April 17, in\n",
      "  retaliation for Japan's alleged failure to stick to a pact not\n",
      "  to sell semiconductors on world markets at below cost.\n",
      "      Unofficial Japanese estimates put the impact of the tariffs\n",
      "  at 10 billion dlrs and spokesmen for major electronics firms\n",
      "  said they would virtually halt exports of products hit by the\n",
      "  new taxes.\n",
      "      \"We wouldn't be able to do business,\" said a spokesman for\n",
      "  leading Japanese electronics firm Matsushita Electric\n",
      "  Industrial Co Ltd &lt;MC.T>.\n",
      "      \"If the tariffs remain in place for any length of time\n",
      "  beyond a few months it will mean the complete erosion of\n",
      "  exports (of goods subject to tariffs) to the U.S.,\" said Tom\n",
      "  Murtha, a stock analyst at the Tokyo office of broker &lt;James\n",
      "  Capel and Co>.\n",
      "      In Taiwan, businessmen and officials are also worried.\n",
      "      \"We are aware of the seriousness of the U.S. Threat against\n",
      "  Japan because it serves as a warning to us,\" said a senior\n",
      "  Taiwanese trade official who asked not to be named.\n",
      "      Taiwan had a trade trade surplus of 15.6 billion dlrs last\n",
      "  year, 95 pct of it with the U.S.\n",
      "      The surplus helped swell Taiwan's foreign exchange reserves\n",
      "  to 53 billion dlrs, among the world's largest.\n",
      "      \"We must quickly open our markets, remove trade barriers and\n",
      "  cut import tariffs to allow imports of U.S. Products, if we\n",
      "  want to defuse problems from possible U.S. Retaliation,\" said\n",
      "  Paul Sheen, chairman of textile exporters &lt;Taiwan Safe Group>.\n",
      "      A senior official of South Korea's trade promotion\n",
      "  association said the trade dispute between the U.S. And Japan\n",
      "  might also lead to pressure on South Korea, whose chief exports\n",
      "  are similar to those of Japan.\n",
      "      Last year South Korea had a trade surplus of 7.1 billion\n",
      "  dlrs with the U.S., Up from 4.9 billion dlrs in 1985.\n",
      "      In Malaysia, trade officers and businessmen said tough\n",
      "  curbs against Japan might allow hard-hit producers of\n",
      "  semiconductors in third countries to expand their sales to the\n",
      "  U.S.\n",
      "      In Hong Kong, where newspapers have alleged Japan has been\n",
      "  selling below-cost semiconductors, some electronics\n",
      "  manufacturers share that view. But other businessmen said such\n",
      "  a short-term commercial advantage would be outweighed by\n",
      "  further U.S. Pressure to block imports.\n",
      "      \"That is a very short-term view,\" said Lawrence Mills,\n",
      "  director-general of the Federation of Hong Kong Industry.\n",
      "      \"If the whole purpose is to prevent imports, one day it will\n",
      "  be extended to other sources. Much more serious for Hong Kong\n",
      "  is the disadvantage of action restraining trade,\" he said.\n",
      "      The U.S. Last year was Hong Kong's biggest export market,\n",
      "  accounting for over 30 pct of domestically produced exports.\n",
      "      The Australian government is awaiting the outcome of trade\n",
      "  talks between the U.S. And Japan with interest and concern,\n",
      "  Industry Minister John Button said in Canberra last Friday.\n",
      "      \"This kind of deterioration in trade relations between two\n",
      "  countries which are major trading partners of ours is a very\n",
      "  serious matter,\" Button said.\n",
      "      He said Australia's concerns centred on coal and beef,\n",
      "  Australia's two largest exports to Japan and also significant\n",
      "  U.S. Exports to that country.\n",
      "      Meanwhile U.S.-Japanese diplomatic manoeuvres to solve the\n",
      "  trade stand-off continue.\n",
      "      Japan's ruling Liberal Democratic Party yesterday outlined\n",
      "  a package of economic measures to boost the Japanese economy.\n",
      "      The measures proposed include a large supplementary budget\n",
      "  and record public works spending in the first half of the\n",
      "  financial year.\n",
      "      They also call for stepped-up spending as an emergency\n",
      "  measure to stimulate the economy despite Prime Minister\n",
      "  Yasuhiro Nakasone's avowed fiscal reform program.\n",
      "      Deputy U.S. Trade Representative Michael Smith and Makoto\n",
      "  Kuroda, Japan's deputy minister of International Trade and\n",
      "  Industry (MITI), are due to meet in Washington this week in an\n",
      "  effort to end the dispute.\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(reuters.raw('test/14826'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f02a78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "summaries = []\n",
    "\n",
    "for file_id in reuters.fileids()[:2000]:\n",
    "    corpus = reuters.raw(file_id)\n",
    "    sentences = nltk.sent_tokenize(corpus)\n",
    "    if len(sentences) > 5:\n",
    "        docs.append(\" \".join(sentences)) # full text\n",
    "        summaries.append(\" \".join(sentences[:3])) # first 3 sentences as summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4bad7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "def tokenize(text):\n",
    "    return [token.text.lower() for token in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c36ca3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yeild_tokens(data):\n",
    "\tfor doc in data:\n",
    "\t\tyield tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d871c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(yeild_tokens(docs+summaries), specials=[\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba18be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = vocab[\"<unk>\"], vocab[\"<pad>\"], vocab[\"<sos>\"], vocab[\"<eos>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78213e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13229"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "355cae96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk>\n",
      "<pad>\n",
      "<sos>\n",
      "<eos>\n",
      "\n",
      "  \n",
      "the\n",
      ",\n",
      ".\n",
      "to\n",
      "of\n",
      "in\n",
      "and\n",
      "a\n",
      "said\n",
      "\"\n",
      "for\n",
      "-\n",
      "'s\n",
      "on\n",
      "it\n"
     ]
    }
   ],
   "source": [
    "# print vocab\n",
    "for i in range(20):\n",
    "\tprint(vocab.get_itos()[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bed8a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryDataset(Dataset):\n",
    "    def __init__(self, docs, summaries, vocab, max_len=100):\n",
    "        self.docs = docs\n",
    "        self.summaries = summaries\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def encode(self, sentence):\n",
    "        tokens = tokenize(sentence)[:self.max_len-2]\n",
    "        return [SOS_IDX] + [self.vocab[token] for token in tokens] + [EOS_IDX]\n",
    "    \n",
    "    def pad(self, seq):\n",
    "        return seq + [PAD_IDX] * (self.max_len - len(seq))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.docs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        src = self.pad(self.encode(self.docs[idx]))\n",
    "        trg = self.pad(self.encode(self.summaries[idx]))\n",
    "        \n",
    "        return torch.tensor(src), torch.tensor(trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdcec918",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SummaryDataset(docs, summaries, vocab)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfdace6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, n_layers, batch_first=True, dropout=dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "\t\t# src : [batch_size, seq_len]\n",
    "        \n",
    "        embedded = self.embedding(src)\n",
    "\t\t# embedded : [batch_size, seq_len, embedding_dim]\n",
    "\n",
    "        output, hidden = self.rnn(embedded)\n",
    "\t\t# output : [batch_size, seq_len, hidden_dim]\n",
    "\t\t# hidden : [n_layers, batch_size, hidden_dim]\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "737684aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, n_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "\t\t# input : [batch_size, seq_len]\n",
    "\t\t# hidden : [n_layers, batch_size, hidden_dim]\n",
    "        \n",
    "        input = input.unsqueeze(1)\n",
    "\t\t# input : [batch_size, 1, seq_len]    # GRU / LSTM expect a 3-D input: (batch, seq_len, input_size) when batch_first=True\n",
    "        \n",
    "        embedded = self.embedding(input)\n",
    "        # embedded : [batch_size, 1, embedding_dim]\n",
    "        \n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        # output : [batch_size, seq_len == 1, hidden_dim]    # because we processed only one step\n",
    "        # hidden : [n_layers, batch_size, hidden_dim]\n",
    "        \n",
    "        prediction = self.fc_out(output.squeeze(1))\n",
    "        # output : [batch_size, hidden_dim]\n",
    "        # prediction : [batch_size, vocab_size]\n",
    "        \n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f87d7928",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        # src : [batch_size, seq_len]\n",
    "        # trg : [batch_size, seq_len]\n",
    "        \n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        vocab_size = self.decoder.fc_out.out_features\n",
    "        \n",
    "        outputs = torch.zeros(batch_size, trg_len, vocab_size).to(self.device)\n",
    "        \n",
    "        hidden = self.encoder(src)\n",
    "        \n",
    "        input = trg[:, 0] # <sos> fed into decoder\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            \n",
    "            outputs[:, t, :] = output\n",
    "            \n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            input = trg[:, t] if teacher_force else output.argmax(1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "431cc360",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(vocab)\n",
    "OUTPUT_DIM = len(vocab)\n",
    "ENC_EMBEDDING_DIM, DEC_EMBEDDING_DIM = 256, 256\n",
    "HIDDEN_DIM = 512\n",
    "ENC_LAYERS, DEC_LAYERS = 3, 3\n",
    "DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMBEDDING_DIM, HIDDEN_DIM, ENC_LAYERS, DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMBEDDING_DIM, HIDDEN_DIM, DEC_LAYERS, DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03ef6662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/10 | LOSS 7.4433\n",
      "EPOCH 2/10 | LOSS 6.6401\n",
      "EPOCH 3/10 | LOSS 6.5612\n",
      "EPOCH 4/10 | LOSS 6.5232\n",
      "EPOCH 5/10 | LOSS 6.4900\n",
      "EPOCH 6/10 | LOSS 6.4725\n",
      "EPOCH 7/10 | LOSS 6.4517\n",
      "EPOCH 8/10 | LOSS 6.4409\n",
      "EPOCH 9/10 | LOSS 6.4235\n",
      "EPOCH 10/10 | LOSS 6.4052\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, (src, trg) in enumerate(data_loader):\n",
    "        \n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg, 0.5) # [batch_size, trg_len, vocab_size]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        \n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    print(f\"EPOCH {epoch+1}/{EPOCHS} | LOSS {epoch_loss/len(data_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "237e4eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "\tmodel.eval()\n",
    "\tepoch_loss = 0\n",
    "\t\n",
    "\twith torch.no_grad():\n",
    "\t\tfor i, (src, trg) in enumerate(data_loader):\n",
    "\t\t\tsrc = src.to(device)\n",
    "\t\t\ttrg = trg.to(device)\n",
    "\t\t\t\n",
    "\t\t\toutput = model(src, trg, 0)\n",
    "\t\t\t\n",
    "\t\t\toutput_dim = output.shape[-1]\n",
    "\t\t\toutput = output[:, 1:].reshape(-1, output_dim)\n",
    "\t\t\t\n",
    "\t\t\ttrg = trg[:, 1:].reshape(-1)\n",
    "\t\t\t\n",
    "\t\t\tloss = criterion(output, trg)\n",
    "\t\t\t\n",
    "\t\t\tepoch_loss += loss.item()\n",
    "\t\n",
    "\treturn epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9dd7c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.323334493135151"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, data_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80eef3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test/14826', 'test/14828', 'test/14829', 'test/14832', 'test/14833']\n"
     ]
    }
   ],
   "source": [
    "print(reuters.fileids()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "358b2e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STOCKS\n",
      "  A survey of 19 provinces and seven cities\n",
      "  showed vermin consume between seven and 12 pct of China's grain\n",
      "  stocks, the China Daily said.\n",
      "      It also said that each year 1.575 mln tonnes, or 25 pct, of\n",
      "  China's fruit output are left to rot, and 2.1 mln tonnes, or up\n",
      "  to 30 pct, of its vegetables. The paper blamed the waste on\n",
      "  inadequate storage and bad preservation methods.\n",
      "      It said the government had launched a national programme to\n",
      "  reduce waste, calling for improved technology in storage and\n",
      "  preservation, and greater production of additives. The paper\n",
      "  gave no further details.\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(reuters.raw('test/14828'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838ad518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(model, text, vocab, max_len=50, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    \n",
    "    # 1. Tokenize & numericalize input\n",
    "    tokens = tokenize(text.lower())[:max_len-2]\n",
    "    src = [SOS_IDX] + [vocab[tok] for tok in tokens] + [EOS_IDX]\n",
    "    src = src + [PAD_IDX] * (max_len - len(src))\n",
    "    src_tensor = torch.tensor(src).unsqueeze(0).to(device)  # (1, seq_len)\n",
    "    \n",
    "    # 2. Encode\n",
    "    with torch.no_grad():\n",
    "        hidden = model.encoder(src_tensor)\n",
    "    \n",
    "    # 3. Start decoding\n",
    "    trg_indexes = [SOS_IDX]   # start with <sos>\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        trg_tensor = torch.tensor([trg_indexes[-1]]).to(device)  # (1,)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, hidden = model.decoder(trg_tensor, hidden)\n",
    "        \n",
    "        # pred_token = output.argmax(1).item()\n",
    "        probs = torch.softmax(output, dim=1)    # convert logits to probabilities \n",
    "        topk_probs, topk_idx = torch.topk(probs, k=5)   # pick top 5 word tokens \n",
    "        pred_token = topk_idx[0][torch.multinomial(topk_probs, 1)]\n",
    "\n",
    "        trg_indexes.append(pred_token)\n",
    "        \n",
    "        if pred_token == EOS_IDX:\n",
    "            break\n",
    "    \n",
    "    # 4. Convert indices back to words\n",
    "    summary_tokens = [vocab.get_itos()[i] for i in trg_indexes[1:]]  # skip <sos>\n",
    "    \n",
    "    return \" \".join([tok for tok in summary_tokens if tok not in [\"<sos>\", \"<eos>\", \"<pad>\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd7606f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary: u.s. & > \n",
      "   > > & \n",
      "   the \n",
      "   \n",
      "   \n",
      "   said \n",
      "   \n",
      "   \n",
      "   of of \n",
      "   \n",
      "   , \n",
      "   \n",
      "   \n",
      "   to to \n",
      "   \n",
      "   \n",
      "   \n",
      "   , \n",
      "   , \n",
      "   the \n",
      "   of , , \n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_text = \"\"\"\n",
    "India's economy grew by 7.8% in the last quarter, driven by strong consumer spending and government investments.\n",
    "Experts say this makes India the fastest-growing major economy in the world, despite global headwinds.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize_text(model, test_text, vocab, max_len=40, device=device)\n",
    "print(\"Generated Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbc22b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary: & & says & \n",
      "   \n",
      "   to \n",
      "   to the the \n",
      "   of \n",
      "   of \n",
      "   the , of \n",
      "   of of \n",
      "   \n",
      "   of to to \n",
      "   , , , the \n",
      "   , \n",
      "   \n",
      "   of \n",
      "   the \n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_text = \"\"\"\n",
    "CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STOCKS\n",
    "  A survey of 19 provinces and seven cities\n",
    "  showed vermin consume between seven and 12 pct of China's grain\n",
    "  stocks, the China Daily said.\n",
    "      It also said that each year 1.575 mln tonnes, or 25 pct, of\n",
    "  China's fruit output are left to rot, and 2.1 mln tonnes, or up\n",
    "  to 30 pct, of its vegetables. The paper blamed the waste on\n",
    "  inadequate storage and bad preservation methods.\n",
    "      It said the government had launched a national programme to\n",
    "  reduce waste, calling for improved technology in storage and\n",
    "  preservation, and greater production of additives. The paper\n",
    "  gave no further details.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize_text(model, test_text, vocab, max_len=40, device=device)\n",
    "print(\"Generated Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb4d2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
