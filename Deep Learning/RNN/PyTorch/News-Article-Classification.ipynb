{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5237a04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aad63d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec764259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:/Intern/DataSets/bbc-text.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e920fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1398f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    doc = nlp(\" \".join(tokens))\n",
    "    tokens = [tokens.lemma_ for tokens in doc if not tokens.is_stop]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24ccf689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleaned_text\"] = df[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f9dc09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [word for token in df[\"cleaned_text\"] for word in token]\n",
    "word_freq = Counter(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4987c400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('say', 8248),\n",
       " ('year', 3312),\n",
       " ('mr', 3005),\n",
       " ('people', 2046),\n",
       " ('new', 1996),\n",
       " ('time', 1585),\n",
       " ('good', 1537),\n",
       " ('m', 1457),\n",
       " ('game', 1453),\n",
       " ('world', 1229)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bc62cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {word : idx+2 for idx, (word, _) in enumerate(word_freq.items())}\n",
    "vocab[\"<PAD>\"] = 0\n",
    "vocab[\"<UNK>\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7395e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(tokens, max_len=100):\n",
    "    return [vocab.get(word, vocab[\"<UNK>\"]) for word in tokens[:max_len]] + [vocab[\"<PAD>\"]] * (max_len - len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "430d60e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 200\n",
    "df[\"encoded_text\"] = df[\"cleaned_text\"].apply(lambda x: encode_text(x, MAX_LEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60d79128",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df[\"label\"] = le.fit_transform(df[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edbab576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>encoded_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "      <td>[tv, future, hand, viewer, home, theatre, syst...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "      <td>[worldcom, boss, leave, book, worldcom, boss, ...</td>\n",
       "      <td>[230, 231, 232, 152, 230, 231, 233, 234, 235, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "      <td>[tiger, wary, farrell, gamble, leicester, rush...</td>\n",
       "      <td>[332, 333, 334, 335, 336, 337, 338, 339, 340, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "      <td>[yeade, face, newcastle, fa, cup, premiership,...</td>\n",
       "      <td>[401, 325, 402, 403, 404, 405, 402, 406, 325, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "      <td>[ocean, raid, box, office, ocean, crime, caper...</td>\n",
       "      <td>[539, 540, 62, 541, 539, 542, 543, 544, 545, 5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text  \\\n",
       "0           tech  tv future in the hands of viewers with home th...   \n",
       "1       business  worldcom boss  left books alone  former worldc...   \n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...   \n",
       "3          sport  yeading face newcastle in fa cup premiership s...   \n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  [tv, future, hand, viewer, home, theatre, syst...   \n",
       "1  [worldcom, boss, leave, book, worldcom, boss, ...   \n",
       "2  [tiger, wary, farrell, gamble, leicester, rush...   \n",
       "3  [yeade, face, newcastle, fa, cup, premiership,...   \n",
       "4  [ocean, raid, box, office, ocean, crime, caper...   \n",
       "\n",
       "                                        encoded_text  label  \n",
       "0  [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...      4  \n",
       "1  [230, 231, 232, 152, 230, 231, 233, 234, 235, ...      0  \n",
       "2  [332, 333, 334, 335, 336, 337, 338, 339, 340, ...      3  \n",
       "3  [401, 325, 402, 403, 404, 405, 402, 406, 325, ...      3  \n",
       "4  [539, 540, 62, 541, 539, 542, 543, 544, 545, 5...      1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90de4653",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "\tdf[\"encoded_text\"].tolist(),\n",
    "\tdf[\"label\"].values,\n",
    "\ttest_size=0.2,\n",
    "\trandom_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec7a0894",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = np.array(labels)   # always numpy\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.texts[idx], dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93871424",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = NewsDataset(X_train, y_train)\n",
    "val_ds = NewsDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9b183e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, output_size, n_layers=1, dropout=0.5):\n",
    "        super(NewsRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, n_layers, batch_first=True, dropout=dropout, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b04cad4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cbdffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NewsRNN(\n",
    "\tvocab_size=len(vocab),\n",
    "\tembed_size=128,\n",
    "\thidden_size=256,\n",
    "\toutput_size=len(df[\"label\"].unique()),\n",
    "\tn_layers=2,\n",
    "\tdropout=0.5\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84759387",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterian = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e9e5c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensors before training\n",
    "def train_loop(model, train_loader, val_loader, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, total_correct = 0, 0\n",
    "        \n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            X_batch = torch.tensor(X_batch).to(device)  # Move to device\n",
    "            y_batch = torch.tensor(y_batch).to(device)  # Move to device\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterian(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_correct += (outputs.argmax(1) == y_batch).sum().item()\n",
    "        \n",
    "        train_acc = total_correct / len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss, val_correct = 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = torch.tensor(X_batch).to(device)  # Move to device\n",
    "                y_batch = torch.tensor(y_batch).to(device)  # Move to device\n",
    "                \n",
    "                outputs = model(X_batch)\n",
    "                loss = criterian(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "                val_correct += (outputs.argmax(1) == y_batch).sum().item()\n",
    "        \n",
    "        val_acc = val_correct / len(val_loader.dataset)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}\", \n",
    "              f\"Train Loss: {total_loss/len(train_loader):.4f}\", \n",
    "              f\"Train Acc: {train_acc:.4f}\",\n",
    "              f\"Val Loss: {val_loss/len(val_loader):.4f}\",\n",
    "              f\"Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1ee1a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14024\\518794196.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch).to(device)  # Move to device\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14024\\518794196.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch).to(device)  # Move to device\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14024\\518794196.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch).to(device)  # Move to device\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14024\\518794196.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch).to(device)  # Move to device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 Train Loss: 1.5650 Train Acc: 0.2787 Val Loss: 1.5505 Val Acc: 0.3236\n",
      "Epoch 2/20 Train Loss: 1.4828 Train Acc: 0.3472 Val Loss: 1.5178 Val Acc: 0.3461\n",
      "Epoch 3/20 Train Loss: 1.3625 Train Acc: 0.4331 Val Loss: 1.4526 Val Acc: 0.3101\n",
      "Epoch 4/20 Train Loss: 1.1376 Train Acc: 0.5264 Val Loss: 1.2028 Val Acc: 0.5056\n",
      "Epoch 5/20 Train Loss: 0.8359 Train Acc: 0.6680 Val Loss: 0.9496 Val Acc: 0.6360\n",
      "Epoch 6/20 Train Loss: 0.5378 Train Acc: 0.8129 Val Loss: 0.6829 Val Acc: 0.7843\n",
      "Epoch 7/20 Train Loss: 0.3276 Train Acc: 0.8955 Val Loss: 0.7670 Val Acc: 0.7483\n",
      "Epoch 8/20 Train Loss: 0.1825 Train Acc: 0.9444 Val Loss: 0.5842 Val Acc: 0.8270\n",
      "Epoch 9/20 Train Loss: 0.1149 Train Acc: 0.9674 Val Loss: 0.6338 Val Acc: 0.8360\n",
      "Epoch 10/20 Train Loss: 0.0754 Train Acc: 0.9820 Val Loss: 0.6149 Val Acc: 0.8449\n",
      "Epoch 11/20 Train Loss: 0.0298 Train Acc: 0.9944 Val Loss: 0.6536 Val Acc: 0.8494\n",
      "Epoch 12/20 Train Loss: 0.0189 Train Acc: 0.9961 Val Loss: 0.6709 Val Acc: 0.8584\n",
      "Epoch 13/20 Train Loss: 0.0241 Train Acc: 0.9927 Val Loss: 0.6894 Val Acc: 0.8382\n",
      "Epoch 14/20 Train Loss: 0.0300 Train Acc: 0.9938 Val Loss: 0.6271 Val Acc: 0.8539\n",
      "Epoch 15/20 Train Loss: 0.0151 Train Acc: 0.9978 Val Loss: 0.6205 Val Acc: 0.8472\n",
      "Epoch 16/20 Train Loss: 0.0053 Train Acc: 0.9994 Val Loss: 0.6184 Val Acc: 0.8697\n",
      "Epoch 17/20 Train Loss: 0.0029 Train Acc: 1.0000 Val Loss: 0.6049 Val Acc: 0.8742\n",
      "Epoch 18/20 Train Loss: 0.0021 Train Acc: 1.0000 Val Loss: 0.6271 Val Acc: 0.8719\n",
      "Epoch 19/20 Train Loss: 0.0016 Train Acc: 1.0000 Val Loss: 0.6392 Val Acc: 0.8764\n",
      "Epoch 20/20 Train Loss: 0.0013 Train Acc: 1.0000 Val Loss: 0.6437 Val Acc: 0.8787\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, train_loader, val_loader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e16fb14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, text, vocab, max_len=200):\n",
    "\tmodel.eval()\n",
    "\ttokens = preprocess_text(text)\n",
    "\tencoded = encode_text(tokens, max_len)\n",
    "\tinput_tensor = torch.tensor(encoded, dtype=torch.long).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "\t\n",
    "\twith torch.no_grad():\n",
    "\t\toutput = model(input_tensor)\n",
    "\t\tpredicted_label = output.argmax(1).item()\n",
    "\t\n",
    "\treturn le.inverse_transform([predicted_label])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acf118fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'politics'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(model, \"The government is planning to introduce new economic reforms to boost growth.\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df509806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'business'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(model, \"Stock markets saw a sharp decline as global oil prices dropped.\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fea9093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sport'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(model, \"The company announced record profits for the second quarter.\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28d37881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tech'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(model, \"Music industry revenues are rising due to online streaming services.\", vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
