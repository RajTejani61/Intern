{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57036095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "190b9366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of Germany?</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
       "      <td>Harper-Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the largest planet in our solar system?</td>\n",
       "      <td>Jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the boiling point of water in Celsius?</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question      answer\n",
       "0                   What is the capital of France?       Paris\n",
       "1                  What is the capital of Germany?      Berlin\n",
       "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
       "3  What is the largest planet in our solar system?     Jupiter\n",
       "4   What is the boiling point of water in Celsius?         100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:/Intern/DataSets/100_Unique_QA_Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9bc43af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efa44218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"'\", \"\")\n",
    "    text = text.strip(\",.?!;:\")\n",
    "    text = text.split()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9348e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocab\n",
    "vocab = {\"<OOV>\": 0}\n",
    "\n",
    "def build_vocab(row):\n",
    "\ttokenized_que = tokenize(row[\"question\"])\n",
    "\ttokenized_ans = tokenize(row[\"answer\"])\n",
    " \n",
    "\tmerged_tokens = tokenized_que + tokenized_ans\n",
    " \n",
    "\tfor token in merged_tokens:\n",
    "\t\tif token not in vocab:\n",
    "\t\t\tvocab[token] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a611fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "      ... \n",
       "85    None\n",
       "86    None\n",
       "87    None\n",
       "88    None\n",
       "89    None\n",
       "Length: 90, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(build_vocab, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7df77c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "470229e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text to sequence\n",
    "def text_to_sequence(text, vocab):\n",
    "\tindexed_text = []\n",
    "\t\n",
    "\tfor token in tokenize(text):\n",
    "\t\tif token in vocab:\n",
    "\t\t\tindexed_text.append(vocab[token])\n",
    "\t\telse:\n",
    "\t\t\tindexed_text.append(vocab[\"<OOV>\"])\n",
    "   \n",
    "\treturn indexed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c883c456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_sequence(\"What is the capital of France?\", vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b460078",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "\tdef __init__(self, df, vocab):\n",
    "\t\tself.df = df\n",
    "\t\tself.vocab = vocab\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.df.shape[0]\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\tseq_question = text_to_sequence(self.df.iloc[index][\"question\"], vocab)\n",
    "\t\tseq_answer = text_to_sequence(self.df.iloc[index][\"answer\"], vocab)\n",
    "\n",
    "\t\treturn torch.tensor(seq_question), torch.tensor(seq_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8599de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QADataset(df, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baf73a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1, 2, 3, 4, 5, 6]), tensor([7]))\n",
      "(tensor([1, 2, 3, 4, 5, 8]), tensor([9]))\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]) # 1st question\n",
    "print(dataset[1]) # 2nd question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32d01408",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b422c963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1,   2,   3,   4,   5, 206]])\n",
      "tensor([[207]])\n"
     ]
    }
   ],
   "source": [
    "for que, ans in dataloader:\n",
    "\tprint(que)\n",
    "\tprint(ans)\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88842bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # architecture\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim=50)\n",
    "        self.rnn = nn.RNN(50, 64, batch_first=True)\n",
    "        self.fc = nn.Linear(64, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded_text = self.embedding(x)\n",
    "        _, final = self.rnn(embedded_text) # returns output of all time steps and last hidden state\n",
    "        output = self.fc(final)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6035ed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(vocab_size)\n",
    "criterian = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "170bb0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 525.479838848114\n",
      "Epoch: 1, Loss: 456.88055658340454\n",
      "Epoch: 2, Loss: 380.80167055130005\n",
      "Epoch: 3, Loss: 322.0150029659271\n",
      "Epoch: 4, Loss: 272.20937633514404\n",
      "Epoch: 5, Loss: 224.77428531646729\n",
      "Epoch: 6, Loss: 181.2981674671173\n",
      "Epoch: 7, Loss: 142.20161765813828\n",
      "Epoch: 8, Loss: 109.85549718141556\n",
      "Epoch: 9, Loss: 84.66838383674622\n",
      "Epoch: 10, Loss: 64.31596612930298\n",
      "Epoch: 11, Loss: 50.12574838101864\n",
      "Epoch: 12, Loss: 39.58172160387039\n",
      "Epoch: 13, Loss: 31.953929141163826\n",
      "Epoch: 14, Loss: 26.58656220883131\n",
      "Epoch: 15, Loss: 21.93062974512577\n",
      "Epoch: 16, Loss: 18.60133097320795\n",
      "Epoch: 17, Loss: 15.996194034814835\n",
      "Epoch: 18, Loss: 13.676321387290955\n",
      "Epoch: 19, Loss: 11.871712025254965\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for que, ans in dataloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #foreward\n",
    "        output = model(que) \n",
    "        #reshape output and target\n",
    "        output = output.view(-1, vocab_size) # size =  (1, vocab_size)\n",
    "        ans = ans.view(-1)\n",
    "        #loss\n",
    "        loss = criterian(output, ans)\n",
    "\t\t#backward\n",
    "        loss.backward()\n",
    "        # update\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch: {epoch}, Loss: {total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f687f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 7.576819896697998\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for que, ans in dataloader:\n",
    "        optput = model(que)\n",
    "        output = output.view(-1, vocab_size)\n",
    "        ans = ans.view(-1)\n",
    "        loss = criterian(output, ans)\n",
    "        print(f\"Loss: {loss.item()}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a41869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, question, threshold=0.5):\n",
    "    # convert que to num\n",
    "\tque = text_to_sequence(question, vocab)\n",
    "\t# tensor\n",
    "\tque = torch.tensor(que)\n",
    "\t# reshape\n",
    "\tque = que.view(1, -1) # (1, seq_len)\n",
    "\t\n",
    "\t# predict\n",
    "\toutput = model(que)\n",
    "\toutput = output.view(-1, vocab_size) # (1, vocab_size)\n",
    "\t\n",
    "\t# convert logits to prob\n",
    "\tprob = torch.nn.functional.softmax(output, dim=1)\n",
    " \n",
    "\t# find index from softmax prob\n",
    "\tvalue, index = torch.max(prob, dim=1)\n",
    " \n",
    "\tif value < threshold:\n",
    "\t\tprint(\"I don't know\")\n",
    "\telse:\n",
    "\t\tprint(\"Answer:\", list(vocab.keys())[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be0e4194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             question    answer\n",
      "56  Which is the second-largest country by land area?    Canada\n",
      "47      What is the longest-running animated TV show?  Simpsons\n",
      "31              Which city is known as the Big Apple?   NewYork\n",
      "43    What is the hardest natural substance on Earth?   Diamond\n",
      "78            Which planet is the closest to the Sun?   Mercury\n"
     ]
    }
   ],
   "source": [
    "print(df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d212ac25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: paris\n",
      "Answer: berlin\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"Where is the capital of France?\")\n",
    "predict(model, \"Where is the capital of Germany?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d328febc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: jupiter\n",
      "Answer: simpsons\n",
      "Answer: newyork\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"What is the largest planet in our solar system?\")\n",
    "predict(model, \"What is the longest-running animated TV show?\")\n",
    "predict(model, \"Which city is known as the Big Apple?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3217328d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
